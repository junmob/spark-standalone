# version: '3.8'

services:

  spark-master:
    container_name: spark-master
    image: spark-image
    build:
      context: .
      target: pyspark
    entrypoint: ['./entrypoint.sh', 'master']
    env_file:
      - .env.spark
    volumes:
      - ./data:/opt/spark/data
      - ./spark_apps:/opt/spark/apps
      - spark-logs:/opt/spark/spark-events
    ports:
      - '9090:8080'     # Master UI
      - '4041:4040'     # Spark Driver
    # - '7077:7077'     # Connection with Worker
    # - '15000:15000'
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080" ]
      interval: 5s
      timeout: 3s
      retries: 3
      start_period: 5s


  spark-worker:
    # container_name: spark-worker
    image: spark-image
    entrypoint: ['./entrypoint.sh', 'worker']
    depends_on:
      spark-master:
        condition: service_healthy
    env_file:
      - .env.spark
    volumes:
      - ./data:/opt/spark/data
      - ./spark_apps:/opt/spark/apps
      - spark-logs:/opt/spark/spark-events
    # ports:
    #   - '8081:8081'


  spark-history-server:
    container_name: spark-history
    image: spark-image
    entrypoint: ['./entrypoint.sh', 'history']
    depends_on:
      spark-master:
        condition: service_healthy
    env_file:
      - .env.spark
    volumes:
      - spark-logs:/opt/spark/spark-events
    ports:
      - '18080:18080'     # Spark History Server UI


  # spark-connect:
  #   image: spark-image
  #   container_name: spark-connect
  #   entrypoint: ['./entrypoint.sh', 'connect']
  #   depends_on:
  #     spark-master:
  #       condition: service_healthy
  #   env_file:
  #     - .env.spark
  #   volumes:
  #     - ./data:/opt/spark/data
  #     - ./spark_apps:/opt/spark/apps
  #     - ./notebooks:/opt/notebooks
  #     - spark-logs:/opt/spark/spark-events
  #   ports:
  #     - '15000:15000'
  #     - '15001:15001'
  #     - '15002:15002'


  spark-jupyter:
    container_name: spark-jupyter
    image: spark-jupyter
    build:
      context: .
      target: jupyter-notebook
    # depends_on:
      # Comment spark-master cuz want to setting up jupyter faster, 
      # and it is not neccessary depends on master.
      # spark-master:
      #   condition: service_healthy      
      # spark-connect:
      #   condition: service_started
    volumes:
      - ./data:/opt/spark/data
      - ./spark_apps:/opt/spark/apps
      - ./notebooks:/opt/notebooks
      - spark-logs:/opt/spark/spark-events
    ports:
      - '8888:8888'     # Jupyter Notebook
      - '4040:4040'     # Spark Driver


volumes:
  spark-logs: